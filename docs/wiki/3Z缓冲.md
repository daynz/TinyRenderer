# Z-Buffer

## 介绍

Z-Buffer，它将帮助我们摆脱上节课中隐藏面移除时出现的视觉伪影。

在理论上，我们可以不丢弃任何三角形就绘制所有三角形。如果我们从后到前正确地进行，前面的面会擦除后面的面。这被称为画家算法。不幸的是，它伴随着高计算成本：对于每次相机移动，我们都需要重新排序整个场景。然后还有动态场景……这甚至不是主要问题。主要问题是并不总是能够确定正确的顺序。

### 尝试渲染一个简单的场景

想象一个由三个三角形组成的简单场景：相机从上往下看，我们将彩色三角形投影到白色屏幕上：

![alt text](image/image-4.png)

渲染应该看起来像这样：

![alt text](image/image-5.png)

蓝色面 - 它在红色面之前还是之后？画家算法在这里不起作用。可以将蓝色面分成两部分（一个在红色面之前，一个在红色面之后）。然后，红色面前面的那一部分需要再分成两部分 - 一个在绿色三角形前面，一个在后面……我想你明白了问题：在有数百万三角形的场景中，计算成本非常高。可以使用BSP树来完成。顺便说一句，这种数据结构对于移动相机是恒定的，但它确实很混乱。而且生命太短暂，不能搞得一团糟。

### Y-buffer

让我们暂时减少一个维度，沿着黄色平面切割上述场景：

![alt text](image/image-6.png)

我的意思是，现在我们的场景由三条线段组成（黄色平面与每个三角形的交点），最终渲染有一个正常的宽度，但只有1像素高度：

![alt text](image/image-7.png)

一如既往，有一个提交可用。我们的场景是二维的，所以很容易使用我们在第一节课中编写的line()函数来绘制它。

```cpp
{ // 只是倾倒2D场景（耶，我们有足够的维度！）
    TGAImage scene(width, height, TGAImage::RGB);

    // 场景“2D网格”
    line(Vec2i(20, 34),   Vec2i(744, 400), scene, red);
    line(Vec2i(120, 434), Vec2i(444, 400), scene, green);
    line(Vec2i(330, 463), Vec2i(594, 200), scene, blue);

    // 屏幕线
    line(Vec2i(10, 10), Vec2i(790, 10), scene, white);

    scene.flip_vertically(); // 我想让原点在图像的左下角
    scene.write_tga_file("scene.tga");
}
```
如果我们侧着看，我们的2D场景就是这样的：

![alt text](image/image-8.png)

让我们渲染它。回想一下，渲染是1像素高度。在我的源代码中，我创建了16像素高度的图像，以便在高分辨率屏幕上阅读。rasterize()函数只写入图像渲染的第一行

```cpp
TGAImage render(width, 16, TGAImage::RGB);
int ybuffer[width];
for (int i=0; i<width; i++) {
    ybuffer[i] = std::numeric_limits<int>::min();
}
rasterize(Vec2i(20, 34),   Vec2i(744, 400), render, red,   ybuffer);
rasterize(Vec2i(120, 434), Vec2i(444, 400), render, green, ybuffer);
rasterize(Vec2i(330, 463), Vec2i(594, 200), render, blue,  ybuffer);
```
所以，我声明了一个维度为（宽度，1）的神奇数组ybuffer。这个数组用负无穷大初始化。然后我调用rasterize()函数，将这个数组和图像渲染作为参数。函数看起来怎么样？

```cpp
void rasterize(Vec2i p0, Vec2i p1, TGAImage &image, TGAColor color, int ybuffer[]) {
    if (p0.x>p1.x) {
        std::swap(p0, p1);
    }
    for (int x=p0.x; x<=p1.x; x++) {
        float t = (x-p0.x)/(float)(p1.x-p0.x);
        int y = p0.y*(1.-t) + p1.y*t;
        if (ybuffer[x]<y) {
            ybuffer[x] = y;
            image.set(x, 0, color);
        }
    }
}
```
这真的很简单：我遍历`p0.x`和`p1.x`之间的所有x坐标，并计算线段的相应y坐标。然后，我检查我们的数组`ybuffer`当前x索引处的内容。如果当前y值比`ybuffer`中的值更接近相机，那么我就在屏幕上绘制它并更新`ybuffer`。

让我们一步一步地看。在调用第一个（红色）线段的`rasterize()`之后，这是我们的记忆：

屏幕：
ybuffer：

这里，品红色表示负无穷大，这些是屏幕我们没有触及的地方。其余的以灰色阴影显示：清晰的彩色接近相机，暗色远离相机。

然后我们绘制绿色线段。

屏幕：
ybuffer：

最后是蓝色线段。

屏幕：
ybuffer：

恭喜，我们刚刚在1D屏幕上绘制了一个2D场景！让我们再次欣赏渲染：

![alt text](image/image-9.png)

### 3D

所以，要在2D屏幕上绘制，z缓冲区必须是二维的：

```cpp
int *zbuffer = new int[width*height];
```
我个人将二维缓冲区打包成一个一维的，转换是微不足道的：

```cpp
int idx = x + y*width;
```
以及后面的一个：

```cpp
int x = idx % width;
int y = idx / width;
```
然后在代码中，我简单地遍历所有三角形，并调用当前三角形和z缓冲区引用的光栅化函数。

唯一的困难是如何计算我们想要绘制的像素的`z`值。让我们回想一下我们是如何计算y缓冲区示例中的`y`值的：

```cpp
int y = p0.y*(1.-t) + p1.y*t;
```
`t`变量的本质是什么？事实证明，`(1-t, t)`是点`(x,y)`相对于线段`p0`, `p1`的重心坐标：`(x,y) = p0*(1-t) + p1*t`。所以，想法是采用三角形光栅化的重心坐标版本，对于我们想要绘制的每个像素，简单地将其重心坐标乘以我们光栅化的三角形的顶点的z值：

```cpp
triangle(screen_coords, float *zbuffer, image, TGAColor(intensity*255, intensity*255, intensity*255, 255));
```
[...]

```cpp
void triangle(Vec3f *pts, float *zbuffer, TGAImage &image, TGAColor color) {
    Vec2f bboxmin( std::numeric_limits<float>::max(),  std::numeric_limits<float>::max());
    Vec2f bboxmax(-std::numeric_limits<float>::max(), -std::numeric_limits<float>::max());
    Vec2f clamp(image.get_width()-1, image.get_height()-1);
    for (int i=0; i<3; i++) {
        for (int j=0; j<2; j++) {
            bboxmin[j] = std::max(0.f,      std::min(bboxmin[j], pts[i][j]));
            bboxmax[j] = std::min(clamp[j], std::max(bboxmax[j], pts[i][j]));
        }
    }
    Vec3f P;
    for (P.x=bboxmin.x; P.x<=bboxmax.x; P.x++) {
        for (P.y=bboxmin.y; P.y<=bboxmax.y; P.y++) {
            Vec3f bc_screen  = barycentric(pts[0], pts[1], pts[2], P);
            if (bc_screen.x<0 || bc_screen.y<0 || bc_screen.z<0) continue;
            P.z = 0;
            for (int i=0; i<3; i++) P.z += pts[i][2]*bc_screen[i];
            if (zbuffer[int(P.x+P.y*width)]<P.z) {
                zbuffer[int(P.x+P.y*width)] = P.z;
                image.set(P.x, P.y, color);
            }
        }
    }
}
```
我们对上节课的源代码做了很少的改动就丢弃了隐藏的部分！这是渲染：

![alt text](image/image-10.png)

好吧，我们刚刚插值了z值。我们还能做什么？
纹理！这将是我们的家庭作业。

在.obj文件中，我们有以"vt u v"开头的行，它们给出了一个纹理坐标数组。在面行"f x/x/x x/x/x x/x/x"中的中间数字（在斜杠之间）是这个三角形的这个顶点的纹理坐标。在三角形内插值，乘以纹理图像的宽度-高度，你将得到要放入你的渲染中的颜色。

漫反射纹理可以在这里获取。

这是你期望的结果：

![alt text](image/image-11.png)